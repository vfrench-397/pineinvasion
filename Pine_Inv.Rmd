---
title: "Pine_Invasion"
output: html_document
---

#Introduction 

#Version Control 



```{r}
library(WGCNA)
library(flashClust)
library(DESeq2)
library(BiocManager)
library(MCMC.OTU)
library(pheatmap)
library(dada2)
library(ShortRead) 
library(ggplot2)
library(phyloseq)
library(Biostrings)
library(data.table)
library(datastorr)
library(fungaltraits)
library(FUNGuildR)
library(jsonlite)
```

#Data Analysis 

#DADA2 Pipeline 

We start with our DADA2 analysis where we input Illumina-sequenced paired-end fastq files that have been demultiplexed by sample. We then run these files through this pipeline to create an amplicon sequence variant (ASV) table which tells us the number of times each unique sequence variant was observed in each sample. We can then assign taxonomy and fungal functional groups to the ASVs to observe fungal community structure in our soil samples. 

Create a variable of our FASTQ files as characters 
```{r}
path <- "/project/bi594/Pine_invasion/rawdata/" #creating variable for file location
fns <- list.files(path) #creates a character vector of FASTQ files in designated path 
fns #sanity check; make sure all files are accounted for 
```

##Trimming and Filtering 

We create and sort the samples. We then divide them into complementary forward (_R1) and reverse (_R2) reads and simplify sample names
```{r}
fastqs <- fns[grepl(".fastq.gz", fns)] #find all .fastq in fns
fastqs <- sort(fastqs) #sorting to ensure samples are in order for downstream analysis 
fnFs <- fastqs[grepl("_R1", fastqs)] 
fnRs <- fastqs[grepl("_R2", fastqs)]
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1) #getting simple sample names; removing .fastq.gz from characters
```

We then specified the path to the forward and reverse fastq files
```{r}
fnFs <- file.path(path, fnFs) 
fnRs <- file.path(path, fnRs)
fnFs
fnRs
```

Plotting Quality profiles to determine truncLen cutoffs for filter and trimming
```{r}
plotQualityProfile(fnFs[c(1:9)])
plotQualityProfile(fnFs[c(10:18)])
plotQualityProfile(fnFs[c(19:27)])
plotQualityProfile(fnFs[c(28:35)])
plotQualityProfile(fnFs[c(36:44)])
plotQualityProfile(fnFs[c(45:53)])
plotQualityProfile(fnFs[c(54:59)])

plotQualityProfile(fnRs[c(1:9)])
plotQualityProfile(fnRs[c(10:18)])
plotQualityProfile(fnRs[c(19:27)])
plotQualityProfile(fnRs[c(28:35)])
plotQualityProfile(fnRs[c(36:44)])
plotQualityProfile(fnRs[c(45:53)])
plotQualityProfile(fnRs[c(54:59)])
```

Creating subdirectory and directing the filtered and trimmed sequences to the specified directory. We then applied the saved sample.names to the filtered sequences. 
```{r}
filt_path <- file.path(path, "trimmed")
if(!file_test("-d", filt_path)) dir.create(filt_path)
filtFs <- file.path(path, "Filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "Filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
```

Checking for presence of primer sequence in order to account for it in filtering. 
```{r}
primerF<-grep("CTTGGTCATTTAGAGGAAGTAA", "RV238_S210_L001_R1_001.fastq.gz") #ITS1F forward primer
primerF
#integer(0) - primer was not found, has already been filtered! Also confirmed in the SCC terminal with grep function
primerR<-grep("GCTGCGTTCTTCATCGATGC", "RV238_S210_L001_R2_001.fastq.gz") #ITS4 reverse primer
primerR
#integer(0) - primer was not found, has already been filtered! Also confirmed in the SCC terminal with grep function
```

Filtering forward and reverse reads with predetermined quality cutoffs. TruncLen was set to 250 for forward reads and 200 for reverse reads based on the dropoff of quality below a quality score of 25, seen in the Quality Profile Plot. Every other parameter was set to the default argument. 
```{r}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen= c(250,200),
                     maxN=0, 
                     maxEE= c(2,2),
                     truncQ=2, 
                     rm.phix=TRUE,
                     compress=TRUE, multithread=FALSE) 
#Must filter reads together to prevent mis-match sorting that can affect merging of forward and reverse reads downstream

#Checking reads.in versus reads.out = Number of reads remaining after filtering with quality scores 
head(out)
tail(out)
```

##Learning Error Rates 

DADA2 was utilized to employ a parametric error model to determine the error rate of the amplicon dataset. We kept the standard max consistency of 30 to increase the number of cycles and allow for convergence.
```{r}
setDadaOpt(MAX_CONSIST=30) 
errF <- learnErrors(filtFs, multithread=TRUE)
errR <- learnErrors(filtRs, multithread=TRUE)
```

Sanity check: We want to visualize error rates and make sure they are following a negative correlation with quality scores
```{r}
plotErrors(errF, nominalQ=TRUE)
plotErrors(errR, nominalQ=TRUE)
#error rates look relatively okay, not strictly linear but definitely a negative correlation 
```

##Dereplicating Reads 

Reads were dereplicated into unique sequences and deseq objects were assigned to sample names
```{r}
derepFs <- derepFastq(filtFs, verbose=FALSE)
derepRs <- derepFastq(filtRs, verbose=FALSE)
names(derepFs) <-sample.names
names(derepRs) <-sample.names
```

##Inferring Sequence Variants 

Applying the joint sample inference algorithm (infers sample sequences exactly and resolves differences of as little as 1 nucleotide) to get a the real variants as a dada class object. We set the band size to 32 as is recommended for ITS2 data. 
```{r}
setDadaOpt(BAND_SIZE=32) 
dadaFs <- dada(derepFs, err=errF, multithread=TRUE)
dadaRs <- dada(derepRs, err=errR, multithread=TRUE)

#Observing the dada class object by sample to identify number of sequence variants 
dadaFs[[1]]
dadaFs[[59]]
```

Denoised forward reads were aligned with reverse-compliment corresponding denoised reverse reads to obtain full sequences

```{r}
mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs, verbose=FALSE)
head(mergers[[1]])
```

Constructing a sequence table (higher resolution otu table) The sequence table is a matrix with rows corresponding to (and named by) the samples, and columns corresponding to (and named by) the sequence variants

```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab) 
head(seqtab)
```

##Removing Chimeras 

Dada accounts for substitution and indel errors but does not remove chimeras. 
```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
#Identified 16 bimeras out of 1871 input sequences
dim(seqtab.nochim)
table(nchar(getSequences(seqtab.nochim))) #distribution of sequence lengths 
sum(seqtab.nochim)/sum(seqtab) 
#Chimeras account for less than 1% of merged sequence variants 
```

Writing the output of the original sequence table and the sequence table with chimeras removed

```{r}
write.csv(seqtab,file="pineinvasion_seqtab.csv")
write.csv(seqtab.nochim,file="pineinvasion_nochim.csv")
```

##Tracking Read Statistics

Producing a csv table output that allows us to track the read statistics throughout the pipeline. It displays the raw reads, how many reads were filtered, denoised, etc. The final number of reads is located under the nonchim column.
```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaFs, getN), rowSums(seqtab), rowSums(seqtab.nochim))
colnames(track) <- c("input", "filtered", "denoised", "merged", "tabled", "nonchim")
rownames(track) <- sample.names 
head(track)
tail(track)
```

Writing the track reads csv
```{r}
write.csv(track,file="ReadFilterStats_AllData_final.csv",row.names=TRUE,quote=FALSE)
```

##Assigning Taxonomy 

We assigned the taxonomy using the UNITE general release reference database for Fungi. This version was released April 2nd 2020. All arguments were kept at default. 
```{r}
taxa <- assignTaxonomy(seqtab.nochim, "/project/bi594/Pine_invasion/sh_general_release_dynamic_s_04.02.2020.fasta", multithread=TRUE)
taxa.print <- taxa
rownames(taxa.print) <- NULL #this gets rid of the sequence column

head(taxa.print) #prints taxonomy; look like fungi
```

Writing the taxa csv file and save reads for the downstream heatmap
```{r}
unname(head(taxa, 30))
unname(taxa)
taxa<- sub('...', '', taxa)
write.csv(taxa, file="taxa.csv",row.name=TRUE,quote=FALSE)

saveRDS(seqtab.nochim, file="final_seqtab_nochim.rds")
saveRDS(taxa, file="final_taxa_blastCorrected.rds")
```

#Phyloseq 

Loading in the previously saved data files and the variable table for phyloseq
```{r}
seqtab.nochim <- readRDS("final_seqtab_nochim.rds")
taxa <- readRDS("final_taxa_blastCorrected.rds")
samdf<-read.csv("variabletable_pi.csv", header = TRUE, sep = ',')
#head and tail the variable table to ensure the same order as sequence table 
head(samdf)
tail(samdf)
rownames(samdf) <- samdf$SAMPLE #making rownames the same as sample names in seq.nochim to merge in phyloseq
```

Constructing the phyloseq object

```{r}
ps <- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE), 
               sample_names(samdf), 
               tax_table(taxa))
ps
```

```{r}
#Collapse the data in the phyloseq object to genus-level IDs
glom <- tax_glom(ps, taxrank = 'Genus')
#Create a dataframe of the OTUs and taxonomic assignments at the genus level
otu<- data.frame(otu_table(glom))
tax_table <- data.frame(tax_table(glom))
#Replace the sequences in the OTU table with corresponding Genus-level IDs
Genus<- tax_table$Genus
colnames(otu) <- Genus
```

Write the OTU that will be used as the input for WGCNA
```{r}
write.csv(otu,file="otu.csv")
```

Generating Abundance Bar plot 

Selecting the Top 90 most abundant taxa
```{r}
top90 <- names(sort(taxa_sums(ps), decreasing=TRUE))[1:90]
ps.top90 <- transform_sample_counts(ps, function(OTU) OTU/sum(OTU))
ps.top90 <- prune_taxa(top90, ps.top90)
```

Write a csv for the phyloseq data to hold the taxa abundances per sample. This will be useful for contructing the downstream heatmap. 
```{r}
psz <- psmelt(ps)
write.csv(psz, file="psz.csv")
psz90 <- psmelt(ps.top90)
write.csv(psz90, file="top90.csv")
```

##Assigning Functional Groups 

Assigning functional groups in Funguild and Fun^fun
```{r}
funguild_input<- data.frame(taxa)
funguild_input$OTU <- row.names(funguild_input)  
funguild_input$Taxonomy <- paste(funguild_input$Kingdom, funguild_input$Phylum, funguild_input$Class, funguild_input$Order, funguild_input$Family, funguild_input$Genus, funguild_input$Species, sep =';')
funguild_input<- subset(funguild_input, select=-c(Kingdom, Phylum, Class, Order, Family, Genus, Species))

guilds<- funguild_assign(funguild_input)
```

Appending the meta-data to the phyloseq data 
```{r}
colnames(psz)[2] <- "SampleID" #rename the sample ID column so we can merge the two dataframes by this column
fulldf <- merge(psz, samdf, by="SampleID")
#do the same for the top 90 taxa
colnames(psz90)[2] <- "SampleID" #rename the sample ID column so we can merge the two dataframes by this column
fulldf90 <- merge(psz90, samdf, by="SampleID")
```

Generating the barplot of fungal abundance by forest type separated by Class
```{r}
p <- ggplot(fulldf, aes(x = site_code, y=Abundance, fill=Class))+ 
  labs(x="Forest type", fill = "Class")
p + geom_bar(stat="identity", colour="black") +
  scale_x_discrete(labels=c('Invaded forest', 'Plantation', "Native forest"))
```


```{r}
ggsave("Abundance_Class.png", path = "/project/bi594/Pine_invasion/Figures/", width=10, height=6, dpi=300)
```

Then we add guild annotations onto the abundance data and generate another barplot of abundance by trophic mode
```{r}
fullguild<- merge(fulldf, guilds, by="OTU")

p2 <- ggplot(fullguild, aes(x = site_code, y=Abundance, fill=trophicMode))+ 
  labs(x="Forest type", fill = "Trophic Mode")
p2 + geom_bar(stat="identity", colour="black") +
  scale_x_discrete(labels=c('Invaded forest', 'Plantation', "Native forest"))
```
```{r}
ggsave("Abundance_Trophic.png", plot=p2, path = "/project/bi594/Pine_invasion/Figures/", width=10, height=6, dpi=300)
```

#Weighted Gene Correlation Network Analysis

Now that we've taken a look at our fungal community data, we'd like to know how the fungal communities relate to soil carbon (C), nitrogen (N), and phosphorus (P). To do this, we use a Weighted Gene Correlation Network Analysis (WGCNA) that will relate the abundance of the genera present in each sample to the C, N, and P of that sample. This analysis will indicate if certain genera are associated with certain soil C, N, and P conditions. 

########################################################################################################
###################Simmi

DATA INPUT AND CLEANING 

#Merge count table with Genus IDs
countData<-read.csv("otu.csv", stringsAsFactors = FALSE)
colnames(countData)[1] = "Sample_ID"

count.trim <- purgeOutliers(countData,count.columns=2:282, otu.cut= .000000000001)
#count.trim <- purgeOutliers(countData,count.columns=2:282)
#Trimmed RV55 sample and a little under 230 taxa; adjust the arguments here; losing too many? too few? 
rownames(count.trim)=count.trim$cdat
count.trim$cdat <- NULL
class(count.trim)

t<- t(as.data.frame(lapply(count.trim,as.numeric)))
colnames(t) <- rownames(count.trim)
class(t) #t transposes data.frame into a matrix 
sapply(t, is.numeric)
ncol(t)
nrow(t)
colnames(t) = c("PL1.1", "PL1.2", "PL1.3", "PL1.4", "PL1.5", "UN1.1", "UN1.2", "UN1.3","UN1.4","UN1.5", "INV1.1", "INV1.2", "INV1.3", "INV1.4", "PL2.1", "PL2.2", "PL2.3", "PL2.4", "PL2.5", "UN2.1", "UN2.3", "UN2.4", "UN2.5", "INV2.1", "INV2.2", "INV2.3", "INV2.4", "INV2.5")

#Read in treatment data
samdf<- read.csv("variabletable_pi.csv")
rownames(samdf)[samdf$SampleID=='RV55'] #insert samples removed from purgeoutliers 
samdf.trim <- samdf[-c(21),]
treat=samdf.trim$site_code
g=data.frame(treat)
g
colData<- g #create coldata for DESeq , **dont really need to do if running blind=TRUE

class(colData)
str(colData)
nrow(colData)


#**running deseq to filter super low counts**
dds<-DESeqDataSetFromMatrix(countData=t, colData=colData, design=~ treat) 

#diagdds = phyloseq_to_deseq2(ps.rarefied, ~ site + position)
gm_mean = function(x, na.rm=TRUE){
  exp(sum(log(x[x > 0]), na.rm=na.rm) / length(x))
}
geoMeans = apply(counts(dds), 1, gm_mean)
dds = estimateSizeFactors(dds, geoMeans = geoMeans)
dds = DESeq(dds, fitType="local")

 
#Not filtering by base mean before rlog transforing the data because basemean filter formatted for gene counts, not OTU abundance data. Filtering previously with purgeOutliers function. 

# get rlog data (better transformation when size factors vary across samples)
rld <- rlogTransformation(dds, blind=TRUE, fitType="local")
#**should be blind=TRUE ? the benefit of wgcna is that it has no idea what our model was so normalize with this function**
#This function transforms the count data to the log2 scale in a way which minimizes differences between samples for rows with small counts, and which normalizes with respect to library size.
head(rld)
rld_wg=(assay(rld)) #Making matrix of rlogTransformation data 
head(rld_wg)
nrow(rld_wg)
#281
rldFiltered=(assay(rld))[(rownames((assay(rld))) %in% rownames(dds)),]
nrow(rldFiltered)
#*filter by the ones removed from res3 function, to get rid of ones without the base mean, do we still do this if we didnt filter
#281

write.csv(rldFiltered,file="Invasion_wgcna_allgenes2.csv",quote=F,row.names=T)
#now we have our filtered data to take into WGCNA

#DATA INPUT AND CLEANING

options(stringsAsFactors=FALSE)

dat=read.csv("Invasion_wgcna_allgenes2.csv")
head(dat) 
rownames(dat)<-dat$X
head(dat)
dat$X=NULL
head(dat)
names(dat)
nrow(dat)
datExpr0 = as.data.frame(t(dat))


### Outlier detection incorporated into trait measures. 
#*make sure trait data is same as Expr0 and names are the same (linking things properly)
traitData= read.csv("Invasion_traits_WGCNA.csv")
rownames(traitData)[traitData$Sample_ID=='RV55'] #insert samples removed from purgeoutliers 
trait.trim <- traitData[-c(21),]
rownames(trait.trim) <- trait.trim$Sample_ID
trait.trim$Sample_ID <- NULL
dim(trait.trim)
head(trait.trim)
names(trait.trim)

# Form a data frame analogous to expression data that will hold the clinical traits.
dim(datExpr0)
rownames(datExpr0)
# datTraits=allTraits
datTraits=trait.trim
row.names(datTraits)= c("PL1.1", "PL1.2", "PL1.3", "PL1.4", "PL1.5", "UN1.1", "UN1.2", "UN1.3","UN1.4","UN1.5", "INV1.1", "INV1.2", "INV1.3", "INV1.4", "PL2.1", "PL2.2", "PL2.3", "PL2.4", "PL2.5", "UN2.1", "UN2.3", "UN2.4", "UN2.5", "INV2.1", "INV2.2", "INV2.3", "INV2.4", "INV2.5")

table(rownames(datTraits)==rownames(datExpr0)) #should return TRUE if datasets align correctly, otherwise your names are out of order
head(datTraits)
head(datExpr0)

#sample dendrogram and trait heat map showing outliers
A=adjacency(t(datExpr0))
k=as.numeric(apply(A,2,sum))-1 #Summing columns of adjacency matrix (-1 to account for self correlation) 
# standardized connectivity
Z.k=scale(k)
thresholdZ.k=-2.5 # often -2.5
outlierColor=ifelse(Z.k<thresholdZ.k,"red","black")
sampleTree = flashClust(as.dist(1-A), method = "average") #**** why did you change from default ("complete")?
# Convert traits to a color representation where red indicates high values
traitColors=data.frame(numbers2colors(datTraits,signed=FALSE))
dimnames(traitColors)[[2]]=paste(names(datTraits))
datColors=data.frame(outlierC=outlierColor,traitColors)
# Plot the sample dendrogram and the colors underneath.
plotDendroAndColors(sampleTree,groupLabels=names(datColors), colors=datColors,main="Sample dendrogram and trait heatmap")
#no outliers 


save(datExpr0,datTraits, file="Invasion_Samples_Traits_ALL2.RData")

#Network Construction and Module Detection 

Setting our working environment and loading in previously saved expression and trait data. 
```{r}
options(stringsAsFactors = FALSE)
lnames = load(file="Invasion_Samples_Traits_ALL2.RData")
```

#Determining the soft power threshold

The Soft power threshold is the power to which co-expression similarity is raised in order to calculate adjacency. It is standard (according to approximate scale-free topology criterion) to select a soft power threshold that corresponds to a scale free topology model fit (R^2) greater than 0.8. If the value of SFT.R.sq does not reach this threshold within a reasonable power (less than 15 for signed data) then the soft power threshold can be decided based on sample size. 

#https://horvath.genetics.ucla.edu/html/CoexpressionNetwork/Rpackages/WGCNA/faq.html

First we must set parameters for a set of cadidate soft-threshold powers to plot and visualize scale independence and mean connectivity. 
```{r}
#Standard setting 
powers = c(seq(1, 10, by = 1), seq(12, 20, by = 2))
#Producing SFT.R.sq way too small
```


```{r}
#adjusting power values just to see if .8 threshold could be reached (it cannot)
#powers = c(seq(100, 190,by=10), seq(200,250, by=5))
```

Plotting Scale Independence and Mean Connectivity to determine soft-power threshold based on the sclae free topology index and mean connectivity as functions of the soft power threshold. 
```{r}
# Call the network topology analysis function
sft = pickSoftThreshold(datExpr0, powerVector = powers, networkType="signed", verbose = 2)
```

```{r}
plot(sft$fitIndices[,1], -sign(sft$fitIndices[,3])*sft$fitIndices[,2],
     xlab="Soft Threshold (power)",ylab="Scale Free Topology Model Fit,signed R^2",type="n",
     main = paste("Scale independence"));
text(sft$fitIndices[,1], -sign(sft$fitIndices[,3])*sft$fitIndices[,2],
     labels=powers,cex=cex1,col="red");
# this line corresponds to using an R^2 cut-off (want it to be between .8 and .9 when selecting sft)
abline(h=0.90,col="red")
```


```{r}
plot(sft$fitIndices[,1], sft$fitIndices[,5],
     xlab="Soft Threshold (power)",ylab="Mean Connectivity", type="n",
     main = paste("Mean connectivity"))
text(sft$fitIndices[,1], sft$fitIndices[,5], labels=powers, cex=cex1,col="red")
```

Because our soft power thresholds never seem to be able to reach a signed R^2 of .8, we decide on the softpower threshold of 16 according to our sample size of 29. 

#https://horvath.genetics.ucla.edu/html/CoexpressionNetwork/Rpackages/WGCNA/faq.html

```{r}
softPower=16 
```

Then we will construct the adjacency matrix that will be utilized to create our initial dendrogram. The adjacency function calculates (correlation or distance) network adjacency from given expression data or from similarity. We want to use signed correlation (this is the default) because we want to create modules with similar abundance patterns for easier biological interpretation of the final output. 
```{r}
adjacency=adjacency(datExpr0, power=softPower,type="signed") 
```

##################Corinne
############################### INITIAL DENDROGRAM ##############################
##Create dendrogram
Now, we want to visualize how the genera group together based on their abundances across samples. For example, genera that regularly appear together in the same samples will cluster together.

We translate the adjacency into a topological overlap matrix and calculate the corresponding dissimilarity:
```{r}
TOM= TOMsimilarity(adjacency,TOMType = "signed")
dissTOM= 1-TOM
```

Then, we create the tree that clusters genera together based on similarity in abundances. Each leaf corresponds to a genus, and branches grouping together densely are genera that frequently occur together. 
```{r}
library(flashClust)
geneTree= flashClust(as.dist(dissTOM), method="average") #do we want to change method back to default?
sizeGrWindow(10,6)
plot(geneTree, xlab="", sub="", main= "Gene Clustering on TOM-based dissimilarity", labels= FALSE,hang=0.04)
```

#*each module gets a number and a size
#*assign color to each module, color represents clusters of coexpressed genes

Next, we set the smallest number of genera that can be included in a module. We chose 5 because there are 281 genera, so higher than 5 would be a very high percentage of all genera. But, less than 5 would be too few genera to consider a cluster.   

```{r}
minModuleSize=5
dynamicMods= cutreeDynamic(dendro= geneTree, distM= dissTOM, deepSplit=2, pamRespectsDendro= FALSE, minClusterSize= minModuleSize)
table(dynamicMods)
```

From this table, we can see that we have 21 modules. 35 taxa were unable to be placed into a module.

Next, we assign colors to each module and plot the colors below the dendrogram to show which branches belong to which module. 

```{r}
dynamicColors= labels2colors(dynamicMods) #assigning colors to each module
sizeGrWindow(8,6)
plotDendroAndColors(geneTree, dynamicColors, "Dynamic Tree Cut", dendroLabels= FALSE, hang=0.03, addGuide= TRUE, guideHang= 0.05, main= "Gene dendrogram and module colors")
```


################ MERGING ##############################
#Merge modules whose expression profiles are very similar, 
#calculate eigengenes
MEList= moduleEigengenes(datExpr0, colors= dynamicColors,softPower = 16) #*will need to change this to the soft threshold decided earlier
MEs= MEList$eigengenes
#Calculate dissimilarity of module eigenegenes
MEDiss= 1-cor(MEs)
#Cluster module eigengenes
METree= flashClust(as.dist(MEDiss), method= "average")

save(dynamicMods, MEList, MEs, MEDiss, METree, file= "Network_invasion_0.7.RData")

lnames = load(file = "Network_invasion_0.7.RData")
#plot
sizeGrWindow(7,6)
plot(METree, main= "Clustering of module eigengenes", xlab= "", sub= "")

MEDissThres= 0.7 #*we can change the threshold of our height, merges them different based on value, dont want to overmerge things that arent that similar
abline(h=MEDissThres, col="red")

merge= mergeCloseModules(datExpr0, dynamicColors, cutHeight= MEDissThres, verbose =1)

mergedColors= merge$colors
mergedMEs= merge$newMEs

pdf(file="MergeNetwork0.7.pdf", width=20, height=20) 
plotDendroAndColors(geneTree, cbind(dynamicColors, mergedColors), c("Dynamic Tree Cut", "Merged dynamic"), dendroLabels= FALSE, hang=0.03, addGuide= TRUE, guideHang=0.05)
dev.off()

moduleColors= mergedColors
colorOrder= c("grey", standardColors(50))
moduleLabels= match(moduleColors, colorOrder)-1
MEs=mergedMEs

#save module colors and labels for use in subsequent parts
save(MEs, moduleLabels, moduleColors, geneTree, file= "Network_signed_0.7.RData")

#############################################################
#Relating modules to traits and finding important genes #I think skip because Taxa already assigned 
library(WGCNA)
# The following setting is important, do not omit.
options(stringsAsFactors = FALSE);
# Load the expression and trait data saved in the first part
#lnames = load(file = "Network_invasion_nomerge.RData");
#The variable lnames contains the names of loaded variables.
#lnames
# Load network data saved in the second part.

#lnames = load(file = "Network_signed_0.6.RData"); #dont load for original non-merging look 
#lnames = load(file = "Network_invasion_nomerge.RData"); #don't load
#lnames

nGenes = ncol(datExpr0)
nSamples = nrow(datExpr0)
table(moduleColors)
#*can pick which colors you want to further explore

# Recalculate MEs with color labels
MEs0 = moduleEigengenes(datExpr0, moduleColors)$eigengenes
MEs = orderMEs(MEs0)
moduleTraitCor = cor(MEs, datTraits, use = "p");
moduleTraitPvalue = corPvalueStudent(moduleTraitCor, nSamples);

####################### MODULE HEATMAP #####################################
#represent module trait correlations as a heatmap

# Will display correlations and their p-values
textMatrix = paste(signif(moduleTraitCor, 2), "\n(",
                   signif(moduleTraitPvalue, 1), ")", sep = "");
dim(textMatrix) = dim(moduleTraitCor)
par(mar = c(6, 8.5, 3, 3));
# Display the correlation values within a heatmap plot
labeledHeatmap(Matrix = moduleTraitCor,
               xLabels = names(datTraits),
               yLabels = names(MEs),
               ySymbols = names(MEs),
               colorLabels = FALSE,
               colors = blueWhiteRed(50),
               textMatrix = textMatrix,
               setStdMargins = FALSE,
               cex.text = 0.5,
               zlim = c(-1,1),
               main = paste("Module-trait relationships"))

#*when see groups of modules that are all hot or all cold, they should be merged. this will have it more likely detect enrichment
#* can change MEDissThres= 0.7 based on this heatmap
#* can see tight correlations, what percentage of variation is explained by certain relationships and look for modules that are doing the same thing

######################### RELATING MODULES TO TRAITS #######################
#Gene relationship to trait and important modules:
# Define variable weight containing the weight column of datTrait - leave weight as variable, but change names in first 2 commands
weight = as.data.frame(datTraits$percC); #change Lipidrobust to your trait name
names(weight) = "percC" 
# names (colors) of the modules
modNames = substring(names(MEs), 3)
geneModuleMembership = as.data.frame(cor(datExpr0, MEs, use = "p"));
MMPvalue = as.data.frame(corPvalueStudent(as.matrix(geneModuleMembership), nSamples));
names(geneModuleMembership) = paste("MM", modNames, sep="");
names(MMPvalue) = paste("p.MM", modNames, sep="");
geneTraitSignificance = as.data.frame(cor(datExpr0, weight, use = "p"));
GSPvalue = as.data.frame(corPvalueStudent(as.matrix(geneTraitSignificance), nSamples));
names(geneTraitSignificance) = paste("GS.", names(weight), sep="");
names(GSPvalue) = paste("p.GS.", names(weight), sep="")

##################### MODULE CORRELATION PLOT ####################
#*how well things belong to module
#Gene-trait significance correlation plots
# par(mfrow=c(2,3))
module = "midnightblue" #*change this to the module we're going to look at
column = match(module, modNames);
moduleGenes = moduleColors==module;
sizeGrWindow(7, 7);
par(mfrow = c(1,1));
verboseScatterplot(abs(geneModuleMembership[moduleGenes, column]),
                   abs(geneTraitSignificance[moduleGenes, 1]),
                   xlab = paste("ModMem in", module, "module"),
                   ylab = "Gene Sig for %C",
                   main = paste("MM vs. GS\n"),
                   cex.main = 1.2, cex.lab = 1.2, cex.axis = 1.2, col = module)

########################## VSD FILES BY MODULE ###################### 
#Making VSD files by module - so we can tell what genera are in each module
vs=t(datExpr0)
cands=names(datExpr0[moduleColors=="midnightblue"]) #*change this also to the color of module we're looking at
#black  blue brown green  grey  pink   red

#*subsetting the genes in this module
c.vsd=vs[rownames(vs) %in% cands,]
head(c.vsd)
nrow(c.vsd) #should correspond to module size
table(moduleColors) #check module sizes here
head(c.vsd)
write.csv(c.vsd,"rlog_MMmidnightblue.csv",quote=F)

#####################KNOW WHICH GENERA ARE IN WHICH MODULE###############
###fisher for GO
##########fisher of module vs whole dataset
#*fisher is binary value of 1  or 0, (1 if in module or 0 if its not)
#*kME is how well that gene belongs to the module 

#Know which genera are in a given module
library(WGCNA)
vsd <- read.csv("Invasion_wgcna_allgenes.csv", row.names=1)
head(vsd)
options(stringsAsFactors=FALSE)
data=t(vsd)
allkME =as.data.frame(signedKME(data, MEs))

whichModule="midnightblue" #*name your color and execute to the end

length(moduleColors)
inModule=data.frame("module"=rep(0,nrow(vsd)))
row.names(inModule)=row.names(vsd)
genes=row.names(vsd)[moduleColors == whichModule]
inModule[genes,1]=1
sum(inModule[,1])
head(inModule)
write.csv(inModule,file=paste(whichModule,"_fisher.csv",sep=""),quote=F)
#*sum is sanity check, should be the same number that was in the module

#know which genera are in each module
yellow <- subset(inModule, module=="1")
yellow <- row.names(yellow)
yellow

grey <- subset(inModule, module=="1")
grey <- row.names(grey)
grey

midnightblue <- subset(inModule, module=="1")
midnightblue <- row.names(midnightblue)
midnightblue

###################### kMEs ###################
#*this gives kME and input for 
#*series of how well gene belongs in module
modColName=paste("kME",whichModule,sep="")
modkME=as.data.frame(allkME[,modColName])
row.names(modkME)=row.names(allkME)
names(modkME)=modColName
write.csv(modkME,file=paste(whichModule,"_kME.csv",sep=""),quote=F)

#make a subset of the yellow kMEs for only the genera in the yellow module
ykmeinput<- paste(yellow, sep=",")
yellowkme<- subset(modkME, rownames(modkME) %in% ykmeinput)
Genus <- rownames(yellowkme)
rownames(yellowkme) <- NULL
yellowkme <- cbind(Genus,yellowkme)

#plot the kMEs to show which genera fit best into the module
ggplot(data= yellowkme, aes(x=reorder(Genus, -kMEyellow), y=kMEyellow)) + 
  geom_bar(color= "black", fill="yellow", stat="identity") +
  theme(axis.text.x=element_text(angle=45,hjust=1,vjust=1)) +
  labs(x="Genus", y="kME")

#########
#make a subset of the midnightblue kMEs for only the genera in the midnightblue module
mbkmeinput<- paste(midnightblue, sep=",")
midnightbluekme<- subset(modkME, rownames(modkME) %in% mbkmeinput)
Genus <- rownames(midnightbluekme)
rownames(midnightbluekme) <- NULL
midnightbluekme <- cbind(Genus,midnightbluekme)

#plot the kMEs to show which genera fit best into the module
ggplot(data= midnightbluekme, aes(x=reorder(Genus, -kMEmidnightblue), y=kMEmidnightblue)) + 
  geom_bar(fill="midnightblue", stat="identity") +
  theme(axis.text.x=element_text(angle=45,hjust=1,vjust=1)) +
  labs(x="Genus", y="kME")


################
#make a subset of the grey kMEs for only the genera in the grey module
gkmeinput<- paste(grey, sep=",")
greykme<- subset(modkME, rownames(modkME) %in% gkmeinput)
Genus <- rownames(greykme)
rownames(greykme) <- NULL
greykme <- cbind(Genus,greykme)

#plot the kMEs to show which genera fit best into the module
ggplot(data= greykme, aes(x=reorder(Genus, -kMEgrey), y=kMEgrey)) + 
  geom_bar(fill="grey", stat="identity") +
  theme(axis.text.x=element_text(angle=45,hjust=1,vjust=1)) +
  labs(x="Genus", y="kME")

######################## HEATMAP OF GENERA ABUNDANCE BY SAMPLE ###################
##############################heatmap of module expression with bar plot of eigengene, no resorting of samples...
#names(dis)
sizeGrWindow(8,7);
which.module="midnightblue" #*change this also to the color of module we're looking at 
#pick module of interest
ME=MEs[, paste("ME",which.module, sep="")]
genes=datExpr0[,moduleColors==which.module ] #replace where says subgene below to plot all rather than just subset

#quartz()
# par(mfrow=c(2,1), mar=c(0.3, 5.5, 3, 2))
par(mfrow=c(2,1), mar=c(0.3, 5.5, 5, 2))
plotMat(t(scale(genes) ),nrgcols=30,rlabels=F, clabels=rownames(genes), rcols=which.module)
par(mar=c(5, 4.2, 0, 0.7))
barplot(ME, col=which.module, main="", cex.main=2,
        ylab="eigengene expression",xlab="sample")
#this is a cool plot where you can see that genes in this module are upregulated in the pH7.5 treatment

###################### HEATMAP OF GENERA ABUNDANCE ORDERED BY TRAIT ##################
##############################heatmap of module expression with bar plot of trait of interest by sample...
#*didnt do this in class but may want to create something that ranks phenotype with gene expression (as traits increase or decrease)
#here we just have binary traits, but if you have a continuous trait this code is cool
sizeGrWindow(8,7);
which.module="midnightblue" #pick module of interest
which.trait="percC" #change trait of interest here
datTraits=datTraits[order((datTraits$percN),decreasing=T),]#change trait of interest here

trait=datTraits[, paste(which.trait)]
genes=datExpr0[,moduleColors==which.module ] #replace where says subgene below to plot all rather than just subset
genes=genes[rownames(datTraits),]

#quartz()
par(mfrow=c(2,1), mar=c(0.3, 5.5, 3, 2))
plotMat(t(scale(genes) ),nrgcols=30,rlabels=F, clabels=rownames(genes), rcols=which.module)
par(mar=c(5, 4.2, 0, 0.7))
barplot(trait, col=which.module, main="", cex.main=2,
        ylab="%C",xlab="sample")#change trait of interest here

#*how well it belongs to module
#Gene relationship to trait and important modules: Gene Significance and Module membership
allkME =as.data.frame(signedKME(t(dat), MEs))
head(allkME)
vsd=read.csv(file="rlog_MMmidnightblue.csv", row.names=1)
head(vsd)
library(pheatmap)

################### TOP 100 HEAT MAP #########################
whichModule="midnightblue" #*color change
top=100
datME=MEs
vsd <- read.csv("Invasion_wgcna_allgenes.csv", row.names=1)
head(vsd)
datExpr=t(vsd)
modcol=paste("kME",whichModule,sep="")
head(vsd)
sorted=vsd[order(allkME[,modcol],decreasing=T),]
hubs=sorted[1:top,]
# attaching gene names
summary(hubs)

contrasting = colorRampPalette(rev(c("chocolate1","#FEE090","grey10", "cyan3","cyan")))(100)
#quartz()
setwd("/project/bi594/Pine_invasion/Figures/")
png(file="pheatmap_midnightblue.png", width=1000, height=1500)
pheatmap(hubs,scale="row",col=contrasting,border_color=NA, main=paste(whichModule,"kME",sep=""))
dev.off()
setwd("/project/bi594/Pine_invasion/")


######--------------------end--------------------#######


